{\rtf1\ansi\ansicpg1252\cocoartf1404\cocoasubrtf340
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
\margl1440\margr1440\vieww10980\viewh9900\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 \ul \ulc0 \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\qc\partightenfactor0

\b \cf0 \ulc0 IEOR 4500: Project 1
\b0 \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 \ulc0 \
\
Part. 1\
\
\ulnone In this part we implemented the power method for estimating the eigenvalues and eigenvectors of a square matrix. We then applied this code to the Russell matrix provided. \
\
\ul Part. 2\
\
\ulnone In this part we computed the covariance of returns matrix using the data set provided for asset prices. To handle the missing entries in the data set we used one of the methods of linear interpolation: we replaced the missing values with the mean of valid surrounding values. We then ran the algorithm implemented for Part 1 on the matrix obtained. \
\
\ul Extra Credit #1\ulnone  \
\
In this part we ran the power method on each of the T-2 covariance matrices obtained by using the first two, three \'85 T days of data (50 day increments). We noticed that in the beginning the eigenvalues were relatively large possibly because of the lack of data. As we increased the number of days we realized the convergence of the eigenvalues to the ones obtained in part 2. \
\
\ul Extra Credit #2\
\
\ulnone In this part we implemented the version of the power method in which we raise the covariance matrix to a high enough k (k being a power of 2). The computation time for this part was 0.65s, approximately 10 times slower than the running time for part 2 (0.06s). For an n x n matrix, the number of operations is in the order of log(k)*n^3 vs k*n^2 for the usual method. So when it comes to choosing the best k, we usually compare the two orders of magnitude. \
\
We obtain the same number of eigenvalues as part 2 given the level of tolerance the user inputs: the first eigenvalues are equal for both parts, however the next ones differ. }